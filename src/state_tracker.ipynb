{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A state is created by the ST as input for the agent to select an appropriate action. It is a numpy array of \n",
    "# useful information from the history of the current conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from db_query import DBQuery\n",
    "import numpy as np\n",
    "from utils import convert_list_to_dict\n",
    "from dialogue_config import all_intents, all_slots, usersim_default_key\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTracker:\n",
    "    \"\"\"Tracks the state of the episode/conversation and prepares the state representation for the agent.\"\"\"\n",
    "\n",
    "    def __init__(self, database, constants):\n",
    "        \"\"\"\n",
    "        The constructor of StateTracker.\n",
    "        The constructor of StateTracker which creates a DB query object, creates necessary state rep. dicts, etc. and\n",
    "        calls reset.\n",
    "        Parameters:\n",
    "            database (dict): The database with format dict(long: dict)\n",
    "            constants (dict): Loaded constants in dict\n",
    "        \"\"\"\n",
    "\n",
    "        self.db_helper = DBQuery(database)\n",
    "        self.match_key = usersim_default_key\n",
    "        self.intents_dict = convert_list_to_dict(all_intents)\n",
    "        self.num_intents = len(all_intents)\n",
    "        self.slots_dict = convert_list_to_dict(all_slots)\n",
    "        self.num_slots = len(all_slots)\n",
    "        self.max_round_num = constants['run']['max_round_num']\n",
    "        self.none_state = np.zeros(self.get_state_size())\n",
    "        self.reset()\n",
    "\n",
    "    def get_state_size(self):\n",
    "        \"\"\"Returns the state size of the state representation used by the agent.\"\"\"\n",
    "\n",
    "        return 2 * self.num_intents + 7 * self.num_slots + 3 + self.max_round_num\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets current_informs, history and round_num.\"\"\"\n",
    "\n",
    "        self.current_informs = {}\n",
    "        # A list of the dialogues (dicts) by the agent and user so far in the conversation\n",
    "        self.history = []\n",
    "        self.round_num = 0\n",
    "\n",
    "    def print_history(self):\n",
    "        \"\"\"Helper function if you want to see the current history action by action.\"\"\"\n",
    "\n",
    "        for action in self.history:\n",
    "            print(action)\n",
    "\n",
    "    def get_state(self, done=False):\n",
    "        \"\"\"\n",
    "        Returns the state representation as a numpy array which is fed into the agent's neural network.\n",
    "        The state representation contains useful information for the agent about the current state of the conversation.\n",
    "        Processes by the agent to be fed into the neural network. Ripe for experimentation and optimization.\n",
    "        Parameters:\n",
    "            done (bool): Indicates whether this is the last dialogue in the episode/conversation. Default: False\n",
    "        Returns:\n",
    "            numpy.array: A numpy array of shape (state size,)\n",
    "        \"\"\"\n",
    "\n",
    "        # If done then fill state with zeros\n",
    "        if done:\n",
    "            return self.none_state\n",
    "        user_action = self.history[-1]\n",
    "        print('Current form : ',self.current_informs)\n",
    "        db_results_dict = self.db_helper.get_db_results_for_slots(self.current_informs)\n",
    "        print('DB Results : ',db_results_dict)\n",
    "        last_agent_action = self.history[-2] if len(self.history) > 1 else None\n",
    "        print('Latest agent action : ',last_agent_action)\n",
    "        # Create one-hot of intents to represent the current user action\n",
    "        user_act_rep = np.zeros((self.num_intents,))\n",
    "        user_act_rep[self.intents_dict[user_action['intent']]] = 1.0\n",
    "        \n",
    "        print('One hot intents user action : ',user_act_rep)\n",
    "        # Create bag of inform slots representation to represent the current user action\n",
    "        user_inform_slots_rep = np.zeros((self.num_slots,))\n",
    "        for key in user_action['inform_slots'].keys():\n",
    "            user_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
    "        \n",
    "        print('Bag of inform slots : ',user_inform_slots_rep)\n",
    "        # Create bag of request slots representation to represent the current user action\n",
    "        user_request_slots_rep = np.zeros((self.num_slots,))\n",
    "        for key in user_action['request_slots'].keys():\n",
    "            user_request_slots_rep[self.slots_dict[key]] = 1.0\n",
    "        \n",
    "        print('Bag of request slots : ',user_request_slots_rep)\n",
    "        # Create bag of filled_in slots based on the current_slots\n",
    "        current_slots_rep = np.zeros((self.num_slots,))\n",
    "        for key in self.current_informs:\n",
    "            current_slots_rep[self.slots_dict[key]] = 1.0\n",
    "\n",
    "        # Encode last agent intent\n",
    "        agent_act_rep = np.zeros((self.num_intents,))\n",
    "        if last_agent_action:\n",
    "            agent_act_rep[self.intents_dict[last_agent_action['intent']]] = 1.0\n",
    "\n",
    "        # Encode last agent inform slots\n",
    "        agent_inform_slots_rep = np.zeros((self.num_slots,))\n",
    "        if last_agent_action:\n",
    "            for key in last_agent_action['inform_slots'].keys():\n",
    "                agent_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
    "\n",
    "        # Encode last agent request slots\n",
    "        agent_request_slots_rep = np.zeros((self.num_slots,))\n",
    "        if last_agent_action:\n",
    "            for key in last_agent_action['request_slots'].keys():\n",
    "                agent_request_slots_rep[self.slots_dict[key]] = 1.0\n",
    "\n",
    "        # Value representation of the round num\n",
    "        turn_rep = np.zeros((1,)) + self.round_num / 5.\n",
    "\n",
    "        # One-hot representation of the round num\n",
    "        turn_onehot_rep = np.zeros((self.max_round_num,))\n",
    "        turn_onehot_rep[self.round_num - 1] = 1.0\n",
    "\n",
    "        # Representation of DB query results (scaled counts)\n",
    "        kb_count_rep = np.zeros((self.num_slots + 1,)) + db_results_dict['matching_all_constraints'] / 100.\n",
    "        for key in db_results_dict.keys():\n",
    "            if key in self.slots_dict:\n",
    "                kb_count_rep[self.slots_dict[key]] = db_results_dict[key] / 100.\n",
    "\n",
    "        # Representation of DB query results (binary)\n",
    "        kb_binary_rep = np.zeros((self.num_slots + 1,)) + np.sum(db_results_dict['matching_all_constraints'] > 0.)\n",
    "        for key in db_results_dict.keys():\n",
    "            if key in self.slots_dict:\n",
    "                kb_binary_rep[self.slots_dict[key]] = np.sum(db_results_dict[key] > 0.)\n",
    "\n",
    "        state_representation = np.hstack(\n",
    "            [user_act_rep, user_inform_slots_rep, user_request_slots_rep, agent_act_rep, agent_inform_slots_rep,\n",
    "             agent_request_slots_rep, current_slots_rep, turn_rep, turn_onehot_rep, kb_binary_rep,\n",
    "             kb_count_rep]).flatten()\n",
    "        print('STATE REPRESENT : ',state_representation)\n",
    "        return state_representation\n",
    "\n",
    "    def update_state_agent(self, agent_action):\n",
    "        \"\"\"\n",
    "        Updates the dialogue history with the agent's action and augments the agent's action.\n",
    "        Takes an agent action and updates the history. Also augments the agent_action param with query information and\n",
    "        any other necessary information.\n",
    "        Parameters:\n",
    "            agent_action (dict): The agent action of format dict('intent': string, 'inform_slots': dict,\n",
    "                                 'request_slots': dict) and changed to dict('intent': '', 'inform_slots': {},\n",
    "                                 'request_slots': {}, 'round': int, 'speaker': 'Agent')\n",
    "        \"\"\"\n",
    "\n",
    "        if agent_action['intent'] == 'inform':\n",
    "            assert agent_action['inform_slots']\n",
    "            inform_slots = self.db_helper.fill_inform_slot(agent_action['inform_slots'], self.current_informs)\n",
    "            agent_action['inform_slots'] = inform_slots\n",
    "            assert agent_action['inform_slots']\n",
    "            key, value = list(agent_action['inform_slots'].items())[0]  # Only one\n",
    "            assert key != 'match_found'\n",
    "            assert value != 'PLACEHOLDER', 'KEY: {}'.format(key)\n",
    "            self.current_informs[key] = value\n",
    "        # If intent is match_found then fill the action informs with the matches informs (if there is a match)\n",
    "        elif agent_action['intent'] == 'match_found':\n",
    "            assert not agent_action['inform_slots'], 'Cannot inform and have intent of match found!'\n",
    "            db_results = self.db_helper.get_db_results(self.current_informs)\n",
    "            if db_results:\n",
    "                # Arbitrarily pick the first value of the dict\n",
    "                key, value = list(db_results.items())[0]\n",
    "                agent_action['inform_slots'] = copy.deepcopy(value)\n",
    "                agent_action['inform_slots'][self.match_key] = str(key)\n",
    "            else:\n",
    "                agent_action['inform_slots'][self.match_key] = 'no match available'\n",
    "            self.current_informs[self.match_key] = agent_action['inform_slots'][self.match_key]\n",
    "        agent_action.update({'round': self.round_num, 'speaker': 'Agent'})\n",
    "        self.history.append(agent_action)\n",
    "\n",
    "    def update_state_user(self, user_action):\n",
    "        \"\"\"\n",
    "        Updates the dialogue history with the user's action and augments the user's action.\n",
    "        Takes a user action and updates the history. Also augments the user_action param with necessary information.\n",
    "        Parameters:\n",
    "            user_action (dict): The user action of format dict('intent': string, 'inform_slots': dict,\n",
    "                                 'request_slots': dict) and changed to dict('intent': '', 'inform_slots': {},\n",
    "                                 'request_slots': {}, 'round': int, 'speaker': 'User')\n",
    "        \"\"\"\n",
    "\n",
    "        for key, value in user_action['inform_slots'].items():\n",
    "            self.current_informs[key] = value\n",
    "        user_action.update({'round': self.round_num, 'speaker': 'User'})\n",
    "        self.history.append(user_action)\n",
    "        self.round_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
